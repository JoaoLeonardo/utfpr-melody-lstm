{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rtx8rb1Rhd60",
        "3mMbXyxc8mz8"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminares\n",
        "\n",
        "Esta rede irá gerar uma lista de notas (tons em MIDI). Os dados do treinamento são do projeto Magenta, em particular a base do Bach Doodle.\n",
        "\n",
        "São utilizadas redes LSTM para gerar as sequencias de notas que possuem tom e tempo."
      ],
      "metadata": {
        "id": "txAUNvcsUOSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# conecta com o Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TF6pfGFH7pnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e00d1d86-0958-4855-d973-fac8ddad64e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports\n",
        "Caso alguma das células falhe, favor verificar os scripts de atualização/instalação de dependências presente na última seção \"Utilidades\"."
      ],
      "metadata": {
        "id": "rtx8rb1Rhd60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importa as dependências gerais\n",
        "import os\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "r-u-JgcAUlxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importa o tensorflow\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.logging.set_verbosity('DEBUG')"
      ],
      "metadata": {
        "id": "Fvf3Q2BEXwZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importa as dependências do magenta\n",
        "import magenta\n",
        "import note_seq\n",
        "\n",
        "from magenta.common import merge_hparams\n",
        "from magenta.contrib import training as contrib_training\n",
        "\n",
        "HParams = contrib_training.HParams\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "from magenta.models.music_vae import data\n",
        "from magenta.models.music_vae import Config\n",
        "from magenta.models.music_vae import lstm_models\n",
        "from magenta.models.music_vae import music_vae_train\n",
        "from magenta.models.music_vae.base_model import MusicVAE\n",
        "from magenta.models.music_vae.trained_model import TrainedModel"
      ],
      "metadata": {
        "id": "1FkwKedUVtJp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82f175c6-40d0-4b99-8710-8b724d34fdbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
            "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
            "  from numba.decorators import jit as optional_jit\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
            "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
            "  from numba.decorators import jit as optional_jit\n",
            "/usr/local/lib/python3.7/dist-packages/resampy/interpn.py:114: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  _resample_loop_p(x, t_out, interp_win, interp_delta, num_table, scale, y)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Declaração de constantes"
      ],
      "metadata": {
        "id": "buezDDiwHNWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 1\n",
        "SHARDS_LEN = 10\n",
        "BATCH_SIZE = 2048\n",
        "OUTPUT_PATH = 'training_dir/data/'\n",
        "\n",
        "current_step = 0"
      ],
      "metadata": {
        "id": "xlEBsWg1HQOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definição das funções de prepação dos lotes"
      ],
      "metadata": {
        "id": "HQ6S304TGope"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_batch_path(index):\n",
        "  return OUTPUT_PATH + \"batch-3-%i.tfrecord\"%(index)"
      ],
      "metadata": {
        "id": "ypXsmEnPjFMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_training_set(dataset_path):\n",
        "  tr_raw_set = tf.data.TFRecordDataset(dataset_path) # 44389 registros\n",
        "  tr_data = tr_raw_set.shuffle(BATCH_SIZE * SHARDS_LEN)\n",
        "\n",
        "  num_shards = SHARDS_LEN\n",
        "\n",
        "  if not os.path.exists(OUTPUT_PATH):\n",
        "      os.makedirs(OUTPUT_PATH)\n",
        "\n",
        "  for i in range(0, SHARDS_LEN):\n",
        "    writer = tf.data.experimental.TFRecordWriter(get_train_batch_path(i))\n",
        "    writer.write(tr_data.shard(SHARDS_LEN, i))"
      ],
      "metadata": {
        "id": "qSPZoWi_GuxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construção dos modelos"
      ],
      "metadata": {
        "id": "3SV4JS73htoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MusicVAE(lstm_models.BidirectionalLstmEncoder(), \n",
        "                 lstm_models.CategoricalLstmDecoder())\n",
        "\n",
        "hparams = merge_hparams(\n",
        "    lstm_models.get_default_hparams(),\n",
        "    HParams(\n",
        "        batch_size=BATCH_SIZE,\n",
        "        max_seq_len=32,  # Divide em 2 compassos com 16 batidas cada\n",
        "        z_size=512,\n",
        "        enc_rnn_size=[2048],\n",
        "        dec_rnn_size=[2048, 2048, 2048],\n",
        "        free_bits=0,\n",
        "        max_beta=0.5,\n",
        "        beta_rate=0.99999,\n",
        "        learning_rate=0.005,\n",
        "        sampling_schedule='inverse_sigmoid',\n",
        "        sampling_rate=1000,\n",
        "        ))\n",
        "\n",
        "augmenter = data.NoteSequenceAugmenter(transpose_range=(-5, 5)),\n",
        "\n",
        "data_converter = data.OneHotMelodyConverter(\n",
        "    skip_polyphony=False,\n",
        "    max_bars=100,\n",
        "    slice_bars=2,\n",
        "    steps_per_quarter=4)"
      ],
      "metadata": {
        "id": "16X7LO1tewi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.build(hparams=hparams, output_depth=data_converter.output_depth, is_training=True)"
      ],
      "metadata": {
        "id": "kbRnyXsAZNT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_config():\n",
        "  global current_step\n",
        "  return Config(\n",
        "    model=model,\n",
        "    hparams=hparams,\n",
        "    #note_sequence_augmenter=augmenter,\n",
        "    data_converter=data_converter,\n",
        "    train_examples_path=get_train_batch_path(current_step),\n",
        "  )"
      ],
      "metadata": {
        "id": "kA0Fwt4maprK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definição das funções de treinamento"
      ],
      "metadata": {
        "id": "TrrhezfOiFG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(tf_file_reader=tf.data.TFRecordDataset):\n",
        "  return data.get_dataset(\n",
        "      get_model_config(),\n",
        "      tf_file_reader=tf_file_reader,\n",
        "      is_training=True,\n",
        "      cache_dataset=False)"
      ],
      "metadata": {
        "id": "3W-JBzpKlkQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step():\n",
        "    run_dir = os.path.expanduser('training_dir')\n",
        "    train_dir = os.path.join(run_dir, 'train')\n",
        "    config = get_model_config()\n",
        "    music_vae_train.train(\n",
        "        train_dir=train_dir,\n",
        "        config=config,\n",
        "        dataset_fn=get_dataset,\n",
        "        num_steps=hparams.batch_size,\n",
        "        checkpoints_to_keep=1,\n",
        "        task=0\n",
        "    )"
      ],
      "metadata": {
        "id": "PW_NZJWrRGGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "  global current_step\n",
        "\n",
        "  for i in range(0, EPOCHS):\n",
        "    current_step = 0;\n",
        "    for j in range (0, SHARDS_LEN):\n",
        "      try:\n",
        "        train_step()\n",
        "        current_step += 1\n",
        "      except:\n",
        "        current_step += 1\n",
        "        pass"
      ],
      "metadata": {
        "id": "sGhrVyQdTr_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Executáveis"
      ],
      "metadata": {
        "id": "AZ-gzHp3iO8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# monta os lotes de treinamento\n",
        "prepare_training_set('drive/MyDrive/BachDoodle/005.tfrecord')"
      ],
      "metadata": {
        "id": "ZG4zYxG2XysS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# execute para treinar o modelo\n",
        "# a partir desse momento não é mais possível preparar os lotes (devido disable_v2_behavior)\n",
        "tf.disable_v2_behavior()\n",
        "train()"
      ],
      "metadata": {
        "id": "C4_rsKH3RO9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instancia o modelo treinado a partir do último checkpoint\n",
        "# OBS: Em caso de erro no deepCopy, favor alterar linha 58 do\n",
        "#      trained_model.py do MusicVAE para self._config = config\n",
        "#      e reiniciar o ambiente de execução\n",
        "trained_model = TrainedModel(\n",
        "    config=get_model_config(), \n",
        "    batch_size=4, \n",
        "    checkpoint_dir_or_path='/content/training_dir/train/model.ckpt-0')"
      ],
      "metadata": {
        "id": "ALazCgkyWVv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# executa o gerador treinado\n",
        "generated_sequences = trained_model.sample(n=4, length=90, temperature=1.0)\n",
        "\n",
        "for ns in generated_sequences:\n",
        "  # print(ns)\n",
        "  note_seq.plot_sequence(ns)"
      ],
      "metadata": {
        "id": "-08kZfFqZ4mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Utilidades...**"
      ],
      "metadata": {
        "id": "3mMbXyxc8mz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instala o magenta\n",
        "!pip install -qU magenta"
      ],
      "metadata": {
        "id": "pO798XHyax_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printa a versão do python\n",
        "!python --version"
      ],
      "metadata": {
        "id": "1UCa7PmrlYpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cria o arquivo de requerimentos\n",
        "!pip freeze >> requierements.txt "
      ],
      "metadata": {
        "id": "KI18qi_9j7WN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cria um .zip dos dados de treinamento\n",
        "import shutil\n",
        "shutil.make_archive('training_dir/train/', 'zip', 'training_dir/train/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3mt24y-ut3se",
        "outputId": "843e3aa1-8920-404f-9521-eece044e951f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/training_dir/train.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copia conteúdos do .zip para o drive\n",
        "!cp training_dir/train.zip /content/drive/MyDrive/LSTM-2"
      ],
      "metadata": {
        "id": "tqg4MdRR2Rtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# conta a quantidade de registros existentes no dataset de treinamento\n",
        "sum(1 for _ in tf.data.TFRecordDataset('training_dir/data/batch-0.tfrecord'))"
      ],
      "metadata": {
        "id": "JuBvuRLTGUHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inspeciona o lote de dados\n",
        "tr_raw_set = tf.data.TFRecordDataset('training_dir/data/batch-0.tfrecord')\n",
        "for raw_record in tr_raw_set.take(1):\n",
        "    example = tf.train.Example()\n",
        "    example.ParseFromString(raw_record.numpy())\n",
        "    print(example)"
      ],
      "metadata": {
        "id": "-f5kFrx4hVS4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}